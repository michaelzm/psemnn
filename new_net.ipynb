{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import Input,Model\n",
    "from tensorflow.keras.layers import Dense, Embedding,  TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import zipfile\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234567890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word embedding with GloVe: load embedding as a dict\n",
    "def load_embedding(filename_embedding,vocabulary,dim=300):\n",
    "    embedding = dict()\n",
    "    with open(filename_embedding,'r', encoding='utf8') as file:\n",
    "        token = '##padding_token##'\n",
    "        embedding[token] = dict()\n",
    "        embedding[token]['vector'] = np.asarray(np.random.rand(dim), dtype='float32')\n",
    "        embedding[token]['token_id'] = int(0)\n",
    "        token_id = 1\n",
    "        for line in tqdm(file):\n",
    "            parts = line.split()\n",
    "            token = parts[0]\n",
    "            if token in vocabulary:\n",
    "                embedding[token] = dict()\n",
    "                embedding[token]['vector'] = np.asarray(parts[1:], dtype='float32')\n",
    "                embedding[token]['token_id'] = int(token_id)\n",
    "                token_id += 1\n",
    "        # add embedding for unknown tokens\n",
    "        token = '##unknown_token##'\n",
    "        embedding[token] = dict()\n",
    "        embedding[token]['vector'] = np.asarray(np.random.rand(dim), dtype='float32')\n",
    "        embedding[token]['token_id'] = int(token_id)\n",
    "        \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tokens_labels_list_to_ids_list(tokens_list, labels_list,embedding, max_seq_length,labelclass_to_id):\n",
    "    token_ids_list, label_ids_list = [], []\n",
    "    n_tags = len(list(labelclass_to_id.keys()))\n",
    "    for index in tqdm(range(len(tokens_list)), desc=\"Converting tokens & labels to ids \"):\n",
    "        tokens = tokens_list[index]\n",
    "        labels = labels_list[index]   \n",
    "        token_ids = []\n",
    "        for token in tokens:\n",
    "            if token not in embedding.keys():\n",
    "                token = '##unknown_token##'\n",
    "            token_ids.append(embedding[token]['token_id'])\n",
    "        label_ids = [labelclass_to_id[label] for label in labels]\n",
    "    \n",
    "        # Zero-pad up to the sequence length.\n",
    "        while len(token_ids) < max_seq_length:\n",
    "            token_ids.append(0)\n",
    "            label_ids.append(0)\n",
    "        token_ids_list.append(token_ids)\n",
    "        label_ids_list.append(label_ids)\n",
    "        \n",
    "    return (\n",
    "        np.array(token_ids_list),\n",
    "        to_categorical(np.array(label_ids_list), num_classes=n_tags),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "# specify the type of information which shall be extracted\n",
    "#extraction_of = 'contexts'\n",
    "extraction_of = 'sentiments'\n",
    "#extraction_of = 'aspects'\n",
    "\n",
    "#sentiment, aspect oder modifier -> diese drei braucht man\n",
    "#extraktion von polarität nicht gefragt\n",
    "\n",
    "\n",
    "# specify filenames in the next line\n",
    "if extraction_of in ['contexts']:\n",
    "    filename = r'data_laptop_ctxt.json'\n",
    "elif extraction_of in ['sentiments','aspects']:\n",
    "    filename = r'data_laptop_absa.json'\n",
    "\n",
    "## in this example, we use the glove word embeddings as input for the neural network\n",
    "## download glove.42B.300d.txt from http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
    "filename_embedding_zip = r'glove.42B.300d.zip' # folder of downloaded glove zip file\n",
    "## specify folder where to store the glove embeddings\n",
    "filepath_embedding = filename_embedding_zip.replace('.zip','')\n",
    "## unzip and save glove to a folder manually or with the next lines\n",
    "if not os.path.exists(filepath_embedding):\n",
    "    with zipfile.ZipFile(filename_embedding_zip,\"r\") as zip_ref:\n",
    "        zip_ref.extractall(filepath_embedding)\n",
    "os.listdir(filepath_embedding)[0]\n",
    "filename_embedding = filepath_embedding + '/' + os.listdir(filepath_embedding)[0]\n",
    "\n",
    "\n",
    "with open(filename,'r', encoding='utf8') as infile:\n",
    "    example_data = json.load(infile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(k,v) in enumerate(example_data.items()):\n",
    "    #print(v.get(\"tokens\"))\n",
    "    tokens = v.get('tokens')\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    example_data[k]['tokens'] = tokens\n",
    "    #key is txtname\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2945.0\n"
     ]
    }
   ],
   "source": [
    "# split 85 15 in train and test tokens\n",
    "#hier die ratio angeben\n",
    "train_test_ratio = 0.95\n",
    "len_dataset = len(example_data) -1\n",
    "\n",
    "split_size = len_dataset * train_test_ratio\n",
    "#split_size -> die anzahl an train datensätzen, rest ist test\n",
    "print(split_size)\n",
    "\n",
    "#hier wird dann anhand der ratio entschieden, ob der aktuelle satz zu train oder test gehört\n",
    "train_tokens = []\n",
    "test_tokens = []\n",
    "for i,(k,v) in  enumerate(example_data.items()):\n",
    "    if i < split_size: \n",
    "      train_tokens.append(v['tokens']) \n",
    "    else:\n",
    "      test_tokens.append(v['tokens'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Ob man union oder inner join nutzt macht echt fast kein unterschied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL USER REVIEWS AS OWN SENTENCE\n",
    "- for that we need to insert each train token array the number of user who reviewed it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433\n",
      "8424\n"
     ]
    }
   ],
   "source": [
    "# split 85 15 in train and test tokens\n",
    "#hier die ratio angeben\n",
    "train_test_ratio = 0.95\n",
    "len_dataset = len(example_data) -1\n",
    "\n",
    "split_size = len_dataset * train_test_ratio\n",
    "#split_size -> die anzahl an train datensätzen, rest ist test\n",
    "\n",
    "#hier wird dann anhand der ratio entschieden, ob der aktuelle satz zu train oder test gehört\n",
    "train_tokens = []\n",
    "test_tokens = []\n",
    "for i,(k,v) in  enumerate(example_data.items()):\n",
    "    curr_users = [s for s in v.keys() if s != \"tokens\"]\n",
    "    insertMul = len(curr_users)\n",
    "    for doTimes in range(insertMul):\n",
    "        if i < split_size: \n",
    "          train_tokens.append(v['tokens']) \n",
    "        else:\n",
    "          test_tokens.append(v['tokens'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be chagend: start\n",
    "# this should be chagend: end\n",
    "train_labels = list()\n",
    "test_labels = list()\n",
    "train_labels_uncertainty = list()\n",
    "for d_idx,(k,v) in enumerate(example_data.items()):\n",
    "    curr_users = [s for s in v.keys() if s !='tokens']         \n",
    "    #jetzt jeden user durchgehen und dessen labels anschauen -> wenn irgendwas außer \"O\", dann \n",
    "    #den oben erstellten array an dieser stelle mit dessen label ersetzen\n",
    "    for usr in curr_users:\n",
    "        #print(usr)\n",
    "        #print(v[usr][extraction_of])\n",
    "        if d_idx < split_size:\n",
    "          #davor v[curr_users[0]][extraction_of], jetzt merged_label\n",
    "          train_labels.append(v[usr][extraction_of])\n",
    "        else:\n",
    "          test_labels.append(v[usr][extraction_of])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8424\n",
      "433\n",
      "8424\n",
      "433\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels))\n",
    "print(len(test_labels))\n",
    "\n",
    "print(len(train_tokens))\n",
    "print(len(test_tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNION on users\n",
    "- always use the sentiment labeling of every user, even if only 1 out of n users labeled the token as sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be chagend: start\n",
    "# this should be chagend: end\n",
    "train_labels = list()\n",
    "test_labels = list()\n",
    "train_labels_uncertainty = list()\n",
    "for d_idx,(k,v) in enumerate(example_data.items()):\n",
    "    curr_users = [s for s in v.keys() if s !='tokens']\n",
    "    \n",
    "    # UNION: ein leeres array erzeugen und mit \"O\" auffüllen\n",
    "    merged_label = []\n",
    "    for i in range(len(v[\"tokens\"])):\n",
    "        #now we have an label array with only O s\n",
    "            merged_label.insert(i, \"O\")\n",
    "            \n",
    "    #jetzt jeden user durchgehen und dessen labels anschauen -> wenn irgendwas außer \"O\", dann \n",
    "    #den oben erstellten array an dieser stelle mit dessen label ersetzen\n",
    "    for usr in curr_users:\n",
    "        #print(usr)\n",
    "        #print(v[usr][extraction_of])\n",
    "        for i,element in enumerate(v[usr][extraction_of]):\n",
    "                if(element != \"O\"):\n",
    "                    del merged_label[i]\n",
    "                    merged_label.insert(i, element)\n",
    "    #print(\"merged to: \" + str(merged_label))\n",
    "    if d_idx < split_size:\n",
    "      #davor v[curr_users[0]][extraction_of], jetzt merged_label\n",
    "      train_labels.append(merged_label)\n",
    "    else:\n",
    "      test_labels.append(merged_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INNER JOIN on users\n",
    "\n",
    "- only iff every user labeled the token the same way we use the labeled value, else we use O instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be chagend: start\n",
    "# this should be chagend: end\n",
    "train_labels = list()\n",
    "test_labels = list()\n",
    "train_labels_uncertainty = list()\n",
    "for d_idx,(k,v) in enumerate(example_data.items()):\n",
    "    curr_users = [s for s in v.keys() if s !='tokens']\n",
    "    merged_label = []\n",
    "    for token_idx in range(len(v[\"tokens\"])):\n",
    "        #print(\"token \"+str(token_idx))\n",
    "        matching = True\n",
    "        #init on value of first user\n",
    "        holder = v[curr_users[0]][extraction_of][token_idx]\n",
    "        #only if all users have the same value, we insert the value\n",
    "        for user_idx in range(len(curr_users)):\n",
    "            #print(\"holder: \"+holder)\n",
    "            #print(\"current choice \"+ str(v[curr_users[user_idx]][extraction_of][token_idx]))\n",
    "            if not v[curr_users[user_idx]][extraction_of][token_idx] == holder:\n",
    "                matching = False\n",
    "        #means all users had the same labeling, so we can insert it\n",
    "        if matching:\n",
    "            merged_label.insert(token_idx, v[curr_users[0]][extraction_of][token_idx])\n",
    "        else:\n",
    "            #otherwise insert O\n",
    "            merged_label.insert(token_idx, \"O\")\n",
    "    #print(\"merged list\")\n",
    "    #print(merged_label)\n",
    "    if d_idx < split_size:\n",
    "      #davor v[curr_users[0]][extraction_of], jetzt merged_label\n",
    "      train_labels.append(merged_label)\n",
    "    else:\n",
    "      test_labels.append(merged_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview over TOKEN in train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test ratio 0.95\n",
      "train data review count: 2945\n",
      "test data review count: 156\n",
      "train token count: 51491\n",
      "test token count: 2860\n",
      "train details: {'0': 43278, 'B_S': 4807, 'I_S': 3406}\n",
      "test details: {'0': 2430, 'B_S': 255, 'I_S': 175}\n"
     ]
    }
   ],
   "source": [
    "print(\"train test ratio \"+str(train_test_ratio))\n",
    "print(\"train data review count: \"+str(len(train_labels)))\n",
    "print(\"test data review count: \"+str(len(test_labels)))\n",
    "sum_train_tokens = 0\n",
    "train_0_count = 0\n",
    "train_B_S_count = 0\n",
    "train_I_S_count = 0\n",
    "train_analysis = {\"0\":0, \"B_S\": 0, \"I_S\": 0}\n",
    "\n",
    "sum_test_tokens = 0\n",
    "test_analysis = {\"0\":0, \"B_S\": 0, \"I_S\": 0}\n",
    "\n",
    "#train analysis\n",
    "for i in range(len(train_labels)):\n",
    "    sum_train_tokens+=len(train_labels[i])\n",
    "    for tok in range(len(train_labels[i])):\n",
    "        token = train_labels[i][tok]\n",
    "        if token == \"O\":\n",
    "            train_analysis[\"0\"] += 1\n",
    "        elif token == \"B_S\":\n",
    "            train_analysis[\"B_S\"] += 1\n",
    "        else:\n",
    "            train_analysis[\"I_S\"] += 1\n",
    "\n",
    "#test analysis\n",
    "for i in range(len(test_labels)):\n",
    "    sum_test_tokens+=len(test_labels[i])\n",
    "    for tok in range(len(test_labels[i])):\n",
    "        token = test_labels[i][tok]\n",
    "        if token == \"O\":\n",
    "            test_analysis[\"0\"] += 1\n",
    "        elif token == \"B_S\":\n",
    "            test_analysis[\"B_S\"] += 1\n",
    "        else:\n",
    "            test_analysis[\"I_S\"] += 1\n",
    "print(\"train token count: \"+str(sum_train_tokens))\n",
    "print(\"test token count: \"+str(sum_test_tokens))\n",
    "print(\"train details: \"+str(train_analysis))\n",
    "print(\"test details: \"+str(test_analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to get an idea of the data we use we can run this snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "labels ['O', 'O', 'B_S', 'O']\n",
      "tokens ['Computer', 'works', 'great', '.']\n",
      "1\n",
      "labels ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_S', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_S', 'I_S', 'O']\n",
      "tokens ['Bough', 'this', 'for', 'the', 'google', 'goodies', 'offers', 'for', 'the', 'holidays', 'but', 'when', 'i', 'go', 'to', 'redeem', 'the', 'offers', 'from', 'the', 'google', 'website', ',', 'it', 'says', 'that', 'this', \"doesn't\", 'have', 'the', 'right', '\"', 'code', '\"', 'to', 'get', 'the', 'drive', 'storage', '.', 'sending', 'back', '.']\n",
      "2\n",
      "labels ['O', 'O', 'O', 'O', 'O', 'B_S', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "tokens ['I', 'am', 'surprised', 'by', 'how', 'well', 'this', 'unit', 'is', 'made', 'and', 'performs', '.']\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0,3):\n",
    "    print(idx)\n",
    "    print(\"labels \"+ str(train_labels[idx]))\n",
    "    print(\"tokens \"+str(train_tokens[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting tokens & labels to ids : 100%|██████████| 2945/2945 [00:00<00:00, 38868.04it/s]\n",
      "Converting tokens & labels to ids : 100%|██████████| 156/156 [00:00<00:00, 39645.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate vocabulary,token ids and embeddings for vocabulary\n",
    "vocabulary = set(['##unknown_token##','##padding_token##'])\n",
    "for v in example_data.values():\n",
    "    vocabulary.update(set(v['tokens']))\n",
    "vocabulary = list(vocabulary)\n",
    "vocabulary.sort()\n",
    "filename_rel_embedding = filename_embedding.replace('.txt','_rel.pkl')\n",
    "if not os.path.exists(filename_rel_embedding):\n",
    "    embedding = load_embedding(filename_embedding, vocabulary)\n",
    "    pickle.dump(embedding,open(filename_rel_embedding,'wb'))\n",
    "else:\n",
    "    embedding = pickle.load(open(filename_rel_embedding,'rb'))\n",
    "vocab_size = len (vocabulary)\n",
    "embed_size = list(embedding.values())[0]['vector'].shape[0]\n",
    "embedding_vectors = np.zeros((vocab_size, embed_size))\n",
    "for v in embedding.values():\n",
    "    vector = v['vector']\n",
    "    token_id = v['token_id']\n",
    "    embedding_vectors[token_id] = vector\n",
    "\n",
    "all_labelclasses = set()\n",
    "for row in train_labels:\n",
    "    all_labelclasses.update(row)\n",
    "all_labelclasses=list(all_labelclasses)\n",
    "all_labelclasses.sort()\n",
    "\n",
    "\n",
    "labelclass_to_id = dict(zip(all_labelclasses,list(range(len(all_labelclasses)))))\n",
    "\n",
    "n_tags = len(list(labelclass_to_id.keys()))\n",
    "\n",
    "\n",
    "max_seq_length = 100\n",
    "\n",
    "# Create datasets (Only take up to max_seq_length words for memory)\n",
    "train_tokens = [t[0:max_seq_length] for t in train_tokens]\n",
    "test_tokens = [t[0:max_seq_length] for t in test_tokens]\n",
    "train_labels = [t[0:max_seq_length] for t in train_labels]\n",
    "test_labels = [t[0:max_seq_length] for t in test_labels]\n",
    "\n",
    "# Convert data to Input format for neural network\n",
    "x_train, y_train = convert_tokens_labels_list_to_ids_list(train_tokens, train_labels, embedding, max_seq_length,labelclass_to_id)\n",
    "x_test, y_test = convert_tokens_labels_list_to_ids_list(test_tokens, test_labels, embedding, max_seq_length,labelclass_to_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## better metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 100, 300)          1694400   \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 100, 3)            903       \n",
      "=================================================================\n",
      "Total params: 1,695,303\n",
      "Trainable params: 903\n",
      "Non-trainable params: 1,694,400\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.2121 - categorical_accuracy: 0.9210 - accuracy: 0.9210 - f1_m: 0.9157 - precision_m: 0.9552 - recall_m: 0.8828 - val_loss: 0.1246 - val_categorical_accuracy: 0.9646 - val_accuracy: 0.9646 - val_f1_m: 0.9654 - val_precision_m: 0.9763 - val_recall_m: 0.9547\n",
      "Epoch 2/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.1051 - categorical_accuracy: 0.9684 - accuracy: 0.9684 - f1_m: 0.9688 - precision_m: 0.9760 - recall_m: 0.9617 - val_loss: 0.0994 - val_categorical_accuracy: 0.9704 - val_accuracy: 0.9704 - val_f1_m: 0.9697 - val_precision_m: 0.9753 - val_recall_m: 0.9642\n",
      "Epoch 3/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0935 - categorical_accuracy: 0.9710 - accuracy: 0.9710 - f1_m: 0.9706 - precision_m: 0.9745 - recall_m: 0.9668 - val_loss: 0.0935 - val_categorical_accuracy: 0.9707 - val_accuracy: 0.9707 - val_f1_m: 0.9714 - val_precision_m: 0.9751 - val_recall_m: 0.9676\n",
      "Epoch 4/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0895 - categorical_accuracy: 0.9713 - accuracy: 0.9713 - f1_m: 0.9716 - precision_m: 0.9748 - recall_m: 0.9684 - val_loss: 0.0906 - val_categorical_accuracy: 0.9707 - val_accuracy: 0.9707 - val_f1_m: 0.9716 - val_precision_m: 0.9753 - val_recall_m: 0.9680\n",
      "Epoch 5/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0871 - categorical_accuracy: 0.9715 - accuracy: 0.9715 - f1_m: 0.9715 - precision_m: 0.9746 - recall_m: 0.9685 - val_loss: 0.0886 - val_categorical_accuracy: 0.9710 - val_accuracy: 0.9710 - val_f1_m: 0.9719 - val_precision_m: 0.9753 - val_recall_m: 0.9685\n",
      "Epoch 6/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0854 - categorical_accuracy: 0.9718 - accuracy: 0.9718 - f1_m: 0.9722 - precision_m: 0.9750 - recall_m: 0.9694 - val_loss: 0.0870 - val_categorical_accuracy: 0.9709 - val_accuracy: 0.9709 - val_f1_m: 0.9721 - val_precision_m: 0.9754 - val_recall_m: 0.9689\n",
      "Epoch 7/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0839 - categorical_accuracy: 0.9721 - accuracy: 0.9721 - f1_m: 0.9719 - precision_m: 0.9747 - recall_m: 0.9692 - val_loss: 0.0857 - val_categorical_accuracy: 0.9712 - val_accuracy: 0.9712 - val_f1_m: 0.9721 - val_precision_m: 0.9753 - val_recall_m: 0.9690\n",
      "Epoch 8/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0828 - categorical_accuracy: 0.9724 - accuracy: 0.9724 - f1_m: 0.9727 - precision_m: 0.9753 - recall_m: 0.9701 - val_loss: 0.0846 - val_categorical_accuracy: 0.9711 - val_accuracy: 0.9711 - val_f1_m: 0.9725 - val_precision_m: 0.9760 - val_recall_m: 0.9691\n",
      "Epoch 9/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0817 - categorical_accuracy: 0.9730 - accuracy: 0.9730 - f1_m: 0.9731 - precision_m: 0.9758 - recall_m: 0.9704 - val_loss: 0.0837 - val_categorical_accuracy: 0.9720 - val_accuracy: 0.9720 - val_f1_m: 0.9729 - val_precision_m: 0.9761 - val_recall_m: 0.9698\n",
      "Epoch 10/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0809 - categorical_accuracy: 0.9733 - accuracy: 0.9733 - f1_m: 0.9732 - precision_m: 0.9757 - recall_m: 0.9708 - val_loss: 0.0828 - val_categorical_accuracy: 0.9728 - val_accuracy: 0.9728 - val_f1_m: 0.9732 - val_precision_m: 0.9766 - val_recall_m: 0.9698\n",
      "Epoch 11/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0801 - categorical_accuracy: 0.9736 - accuracy: 0.9736 - f1_m: 0.9736 - precision_m: 0.9762 - recall_m: 0.9710 - val_loss: 0.0821 - val_categorical_accuracy: 0.9731 - val_accuracy: 0.9731 - val_f1_m: 0.9734 - val_precision_m: 0.9770 - val_recall_m: 0.9699\n",
      "Epoch 12/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0795 - categorical_accuracy: 0.9738 - accuracy: 0.9738 - f1_m: 0.9738 - precision_m: 0.9762 - recall_m: 0.9713 - val_loss: 0.0816 - val_categorical_accuracy: 0.9731 - val_accuracy: 0.9731 - val_f1_m: 0.9738 - val_precision_m: 0.9768 - val_recall_m: 0.9707\n",
      "Epoch 13/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0789 - categorical_accuracy: 0.9738 - accuracy: 0.9738 - f1_m: 0.9739 - precision_m: 0.9765 - recall_m: 0.9714 - val_loss: 0.0811 - val_categorical_accuracy: 0.9733 - val_accuracy: 0.9733 - val_f1_m: 0.9742 - val_precision_m: 0.9777 - val_recall_m: 0.9708\n",
      "Epoch 14/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0784 - categorical_accuracy: 0.9744 - accuracy: 0.9744 - f1_m: 0.9740 - precision_m: 0.9768 - recall_m: 0.9713 - val_loss: 0.0806 - val_categorical_accuracy: 0.9738 - val_accuracy: 0.9738 - val_f1_m: 0.9744 - val_precision_m: 0.9778 - val_recall_m: 0.9710\n",
      "Epoch 15/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0780 - categorical_accuracy: 0.9744 - accuracy: 0.9744 - f1_m: 0.9743 - precision_m: 0.9768 - recall_m: 0.9719 - val_loss: 0.0803 - val_categorical_accuracy: 0.9740 - val_accuracy: 0.9740 - val_f1_m: 0.9746 - val_precision_m: 0.9777 - val_recall_m: 0.9716\n",
      "Epoch 16/50\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.0775 - categorical_accuracy: 0.9745 - accuracy: 0.9745 - f1_m: 0.9741 - precision_m: 0.9767 - recall_m: 0.9715 - val_loss: 0.0799 - val_categorical_accuracy: 0.9739 - val_accuracy: 0.9739 - val_f1_m: 0.9747 - val_precision_m: 0.9779 - val_recall_m: 0.9716\n",
      "Epoch 17/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0772 - categorical_accuracy: 0.9746 - accuracy: 0.9746 - f1_m: 0.9745 - precision_m: 0.9771 - recall_m: 0.9718 - val_loss: 0.0797 - val_categorical_accuracy: 0.9740 - val_accuracy: 0.9740 - val_f1_m: 0.9750 - val_precision_m: 0.9786 - val_recall_m: 0.9715\n",
      "Epoch 18/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0769 - categorical_accuracy: 0.9746 - accuracy: 0.9746 - f1_m: 0.9749 - precision_m: 0.9777 - recall_m: 0.9722 - val_loss: 0.0793 - val_categorical_accuracy: 0.9742 - val_accuracy: 0.9742 - val_f1_m: 0.9753 - val_precision_m: 0.9787 - val_recall_m: 0.9719\n",
      "Epoch 19/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0765 - categorical_accuracy: 0.9748 - accuracy: 0.9748 - f1_m: 0.9749 - precision_m: 0.9776 - recall_m: 0.9722 - val_loss: 0.0790 - val_categorical_accuracy: 0.9746 - val_accuracy: 0.9746 - val_f1_m: 0.9753 - val_precision_m: 0.9787 - val_recall_m: 0.9720\n",
      "Epoch 20/50\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 0.0762 - categorical_accuracy: 0.9750 - accuracy: 0.9750 - f1_m: 0.9753 - precision_m: 0.9778 - recall_m: 0.9728 - val_loss: 0.0789 - val_categorical_accuracy: 0.9751 - val_accuracy: 0.9751 - val_f1_m: 0.9755 - val_precision_m: 0.9789 - val_recall_m: 0.9722\n",
      "Epoch 21/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0759 - categorical_accuracy: 0.9752 - accuracy: 0.9752 - f1_m: 0.9752 - precision_m: 0.9777 - recall_m: 0.9727 - val_loss: 0.0787 - val_categorical_accuracy: 0.9750 - val_accuracy: 0.9750 - val_f1_m: 0.9756 - val_precision_m: 0.9788 - val_recall_m: 0.9725\n",
      "Epoch 22/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0757 - categorical_accuracy: 0.9753 - accuracy: 0.9753 - f1_m: 0.9755 - precision_m: 0.9779 - recall_m: 0.9731 - val_loss: 0.0786 - val_categorical_accuracy: 0.9750 - val_accuracy: 0.9750 - val_f1_m: 0.9758 - val_precision_m: 0.9789 - val_recall_m: 0.9727\n",
      "Epoch 23/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0754 - categorical_accuracy: 0.9755 - accuracy: 0.9755 - f1_m: 0.9757 - precision_m: 0.9782 - recall_m: 0.9733 - val_loss: 0.0783 - val_categorical_accuracy: 0.9750 - val_accuracy: 0.9750 - val_f1_m: 0.9760 - val_precision_m: 0.9789 - val_recall_m: 0.9731\n",
      "Epoch 24/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0752 - categorical_accuracy: 0.9756 - accuracy: 0.9756 - f1_m: 0.9756 - precision_m: 0.9780 - recall_m: 0.9732 - val_loss: 0.0782 - val_categorical_accuracy: 0.9750 - val_accuracy: 0.9750 - val_f1_m: 0.9760 - val_precision_m: 0.9790 - val_recall_m: 0.9731\n",
      "Epoch 25/50\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.0750 - categorical_accuracy: 0.9756 - accuracy: 0.9756 - f1_m: 0.9755 - precision_m: 0.9778 - recall_m: 0.9732 - val_loss: 0.0782 - val_categorical_accuracy: 0.9751 - val_accuracy: 0.9751 - val_f1_m: 0.9760 - val_precision_m: 0.9793 - val_recall_m: 0.9728\n",
      "Epoch 26/50\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.0748 - categorical_accuracy: 0.9757 - accuracy: 0.9757 - f1_m: 0.9761 - precision_m: 0.9785 - recall_m: 0.9738 - val_loss: 0.0779 - val_categorical_accuracy: 0.9749 - val_accuracy: 0.9749 - val_f1_m: 0.9761 - val_precision_m: 0.9791 - val_recall_m: 0.9730\n",
      "Epoch 27/50\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.0746 - categorical_accuracy: 0.9758 - accuracy: 0.9758 - f1_m: 0.9757 - precision_m: 0.9781 - recall_m: 0.9733 - val_loss: 0.0779 - val_categorical_accuracy: 0.9749 - val_accuracy: 0.9749 - val_f1_m: 0.9762 - val_precision_m: 0.9793 - val_recall_m: 0.9732\n",
      "Epoch 28/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0744 - categorical_accuracy: 0.9758 - accuracy: 0.9758 - f1_m: 0.9761 - precision_m: 0.9784 - recall_m: 0.9739 - val_loss: 0.0778 - val_categorical_accuracy: 0.9749 - val_accuracy: 0.9749 - val_f1_m: 0.9762 - val_precision_m: 0.9793 - val_recall_m: 0.9731\n",
      "Epoch 29/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0742 - categorical_accuracy: 0.9760 - accuracy: 0.9760 - f1_m: 0.9760 - precision_m: 0.9782 - recall_m: 0.9738 - val_loss: 0.0779 - val_categorical_accuracy: 0.9751 - val_accuracy: 0.9751 - val_f1_m: 0.9762 - val_precision_m: 0.9793 - val_recall_m: 0.9731\n",
      "Epoch 30/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0742 - categorical_accuracy: 0.9761 - accuracy: 0.9761 - f1_m: 0.9763 - precision_m: 0.9786 - recall_m: 0.9740 - val_loss: 0.0775 - val_categorical_accuracy: 0.9750 - val_accuracy: 0.9750 - val_f1_m: 0.9763 - val_precision_m: 0.9791 - val_recall_m: 0.9734\n",
      "Epoch 31/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0739 - categorical_accuracy: 0.9762 - accuracy: 0.9762 - f1_m: 0.9763 - precision_m: 0.9784 - recall_m: 0.9742 - val_loss: 0.0776 - val_categorical_accuracy: 0.9753 - val_accuracy: 0.9753 - val_f1_m: 0.9763 - val_precision_m: 0.9791 - val_recall_m: 0.9734\n",
      "Epoch 32/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0738 - categorical_accuracy: 0.9762 - accuracy: 0.9762 - f1_m: 0.9765 - precision_m: 0.9786 - recall_m: 0.9745 - val_loss: 0.0774 - val_categorical_accuracy: 0.9752 - val_accuracy: 0.9752 - val_f1_m: 0.9762 - val_precision_m: 0.9790 - val_recall_m: 0.9736\n",
      "Epoch 33/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0737 - categorical_accuracy: 0.9762 - accuracy: 0.9762 - f1_m: 0.9764 - precision_m: 0.9784 - recall_m: 0.9744 - val_loss: 0.0773 - val_categorical_accuracy: 0.9751 - val_accuracy: 0.9751 - val_f1_m: 0.9761 - val_precision_m: 0.9787 - val_recall_m: 0.9736\n",
      "Epoch 34/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0735 - categorical_accuracy: 0.9763 - accuracy: 0.9763 - f1_m: 0.9765 - precision_m: 0.9784 - recall_m: 0.9745 - val_loss: 0.0774 - val_categorical_accuracy: 0.9754 - val_accuracy: 0.9754 - val_f1_m: 0.9762 - val_precision_m: 0.9791 - val_recall_m: 0.9733\n",
      "Epoch 35/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0734 - categorical_accuracy: 0.9763 - accuracy: 0.9763 - f1_m: 0.9759 - precision_m: 0.9779 - recall_m: 0.9740 - val_loss: 0.0776 - val_categorical_accuracy: 0.9755 - val_accuracy: 0.9755 - val_f1_m: 0.9761 - val_precision_m: 0.9791 - val_recall_m: 0.9731\n",
      "Epoch 36/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0734 - categorical_accuracy: 0.9764 - accuracy: 0.9764 - f1_m: 0.9766 - precision_m: 0.9786 - recall_m: 0.9747 - val_loss: 0.0772 - val_categorical_accuracy: 0.9755 - val_accuracy: 0.9755 - val_f1_m: 0.9762 - val_precision_m: 0.9788 - val_recall_m: 0.9735\n",
      "Epoch 37/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0732 - categorical_accuracy: 0.9764 - accuracy: 0.9764 - f1_m: 0.9764 - precision_m: 0.9783 - recall_m: 0.9745 - val_loss: 0.0773 - val_categorical_accuracy: 0.9757 - val_accuracy: 0.9757 - val_f1_m: 0.9761 - val_precision_m: 0.9789 - val_recall_m: 0.9733\n",
      "Epoch 38/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0731 - categorical_accuracy: 0.9764 - accuracy: 0.9764 - f1_m: 0.9767 - precision_m: 0.9786 - recall_m: 0.9747 - val_loss: 0.0770 - val_categorical_accuracy: 0.9760 - val_accuracy: 0.9760 - val_f1_m: 0.9761 - val_precision_m: 0.9787 - val_recall_m: 0.9736\n",
      "Epoch 39/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0730 - categorical_accuracy: 0.9764 - accuracy: 0.9764 - f1_m: 0.9767 - precision_m: 0.9785 - recall_m: 0.9748 - val_loss: 0.0770 - val_categorical_accuracy: 0.9758 - val_accuracy: 0.9758 - val_f1_m: 0.9761 - val_precision_m: 0.9788 - val_recall_m: 0.9735\n",
      "Epoch 40/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0729 - categorical_accuracy: 0.9764 - accuracy: 0.9764 - f1_m: 0.9768 - precision_m: 0.9787 - recall_m: 0.9750 - val_loss: 0.0768 - val_categorical_accuracy: 0.9759 - val_accuracy: 0.9759 - val_f1_m: 0.9761 - val_precision_m: 0.9785 - val_recall_m: 0.9738\n",
      "Epoch 41/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0728 - categorical_accuracy: 0.9764 - accuracy: 0.9764 - f1_m: 0.9763 - precision_m: 0.9782 - recall_m: 0.9744 - val_loss: 0.0769 - val_categorical_accuracy: 0.9758 - val_accuracy: 0.9758 - val_f1_m: 0.9763 - val_precision_m: 0.9788 - val_recall_m: 0.9739\n",
      "Epoch 42/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0727 - categorical_accuracy: 0.9765 - accuracy: 0.9765 - f1_m: 0.9768 - precision_m: 0.9787 - recall_m: 0.9748 - val_loss: 0.0767 - val_categorical_accuracy: 0.9759 - val_accuracy: 0.9759 - val_f1_m: 0.9763 - val_precision_m: 0.9785 - val_recall_m: 0.9741\n",
      "Epoch 43/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0726 - categorical_accuracy: 0.9764 - accuracy: 0.9764 - f1_m: 0.9762 - precision_m: 0.9782 - recall_m: 0.9742 - val_loss: 0.0767 - val_categorical_accuracy: 0.9762 - val_accuracy: 0.9762 - val_f1_m: 0.9765 - val_precision_m: 0.9787 - val_recall_m: 0.9743\n",
      "Epoch 44/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0726 - categorical_accuracy: 0.9765 - accuracy: 0.9765 - f1_m: 0.9764 - precision_m: 0.9784 - recall_m: 0.9745 - val_loss: 0.0769 - val_categorical_accuracy: 0.9761 - val_accuracy: 0.9761 - val_f1_m: 0.9765 - val_precision_m: 0.9788 - val_recall_m: 0.9742\n",
      "Epoch 45/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0725 - categorical_accuracy: 0.9766 - accuracy: 0.9766 - f1_m: 0.9769 - precision_m: 0.9788 - recall_m: 0.9750 - val_loss: 0.0766 - val_categorical_accuracy: 0.9762 - val_accuracy: 0.9762 - val_f1_m: 0.9766 - val_precision_m: 0.9788 - val_recall_m: 0.9743\n",
      "Epoch 46/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0724 - categorical_accuracy: 0.9766 - accuracy: 0.9766 - f1_m: 0.9767 - precision_m: 0.9786 - recall_m: 0.9749 - val_loss: 0.0766 - val_categorical_accuracy: 0.9762 - val_accuracy: 0.9762 - val_f1_m: 0.9765 - val_precision_m: 0.9787 - val_recall_m: 0.9744\n",
      "Epoch 47/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0724 - categorical_accuracy: 0.9766 - accuracy: 0.9766 - f1_m: 0.9769 - precision_m: 0.9789 - recall_m: 0.9750 - val_loss: 0.0769 - val_categorical_accuracy: 0.9758 - val_accuracy: 0.9758 - val_f1_m: 0.9763 - val_precision_m: 0.9787 - val_recall_m: 0.9738\n",
      "Epoch 48/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0723 - categorical_accuracy: 0.9766 - accuracy: 0.9766 - f1_m: 0.9768 - precision_m: 0.9788 - recall_m: 0.9749 - val_loss: 0.0767 - val_categorical_accuracy: 0.9760 - val_accuracy: 0.9760 - val_f1_m: 0.9765 - val_precision_m: 0.9787 - val_recall_m: 0.9743\n",
      "Epoch 49/50\n",
      "93/93 [==============================] - 0s 4ms/step - loss: 0.0723 - categorical_accuracy: 0.9766 - accuracy: 0.9766 - f1_m: 0.9767 - precision_m: 0.9788 - recall_m: 0.9747 - val_loss: 0.0766 - val_categorical_accuracy: 0.9761 - val_accuracy: 0.9761 - val_f1_m: 0.9764 - val_precision_m: 0.9787 - val_recall_m: 0.9742\n",
      "Epoch 50/50\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 0.0722 - categorical_accuracy: 0.9767 - accuracy: 0.9767 - f1_m: 0.9765 - precision_m: 0.9784 - recall_m: 0.9745 - val_loss: 0.0766 - val_categorical_accuracy: 0.9760 - val_accuracy: 0.9760 - val_f1_m: 0.9763 - val_precision_m: 0.9787 - val_recall_m: 0.9740\n"
     ]
    }
   ],
   "source": [
    "# neural network model in keras\n",
    "# see keras documentation for functions of different layers and structure of networks.\n",
    "\n",
    "# the following two layers should not be changed.\n",
    "input_layer = Input(shape=(max_seq_length,))\n",
    "embedding_layer = Embedding(vocab_size, 300, weights=[embedding_vectors], input_length=max_seq_length, trainable= False)(input_layer)\n",
    "\n",
    "# here, attention models have to be implemented in this model\n",
    "# ...\n",
    "\n",
    "# this last layer can/should be modified\n",
    "output_layer = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(embedding_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"categorical_accuracy\", \"accuracy\", f1_m,precision_m, recall_m])\n",
    "model.summary()\n",
    "\n",
    "# fit model on train data\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          #validation_split = 0.2,\n",
    "          verbose = 1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle = True,\n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GIVEN EVAL\n",
    "- scheme provided by university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_S_pred</th>\n",
       "      <th>I_S_pred</th>\n",
       "      <th>O_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B_S_true</th>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I_S_true</th>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O_true</th>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2393.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          B_S_pred  I_S_pred  O_pred\n",
       "B_S_true      88.0       1.0   166.0\n",
       "I_S_true      17.0       5.0   153.0\n",
       "O_true        33.0       4.0  2393.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check gt 0\n",
      "88.0\n",
      "\n",
      "CLASS = 0\n",
      "precision\n",
      "0.6376811594202898\n",
      "recall\n",
      "0.34509803921568627\n",
      "f1\n",
      "0.44783715012722647\n",
      "check gt 0\n",
      "5.0\n",
      "\n",
      "CLASS = 1\n",
      "precision\n",
      "0.5\n",
      "recall\n",
      "0.02857142857142857\n",
      "f1\n",
      "0.05405405405405405\n",
      "check gt 0\n",
      "2393.0\n",
      "\n",
      "CLASS = 2\n",
      "precision\n",
      "0.8823746312684366\n",
      "recall\n",
      "0.9847736625514403\n",
      "f1\n",
      "0.9307662388175807\n",
      "\n",
      "Precision: 0.6733519302295754\n",
      "Recall: 0.45281437677951836\n",
      "F1-measure: 0.5414891792491335\n",
      "\n",
      "\n",
      "dict_keys(['loss', 'categorical_accuracy', 'accuracy', 'f1_m', 'precision_m', 'recall_m', 'val_loss', 'val_categorical_accuracy', 'val_accuracy', 'val_f1_m', 'val_precision_m', 'val_recall_m'])\n"
     ]
    }
   ],
   "source": [
    "## evaluation\n",
    "# predict labels of test data\n",
    "y_test_pred_prob = model.predict(x_test)\n",
    "y_test_pred_sparse = y_test_pred_prob.argmax(axis=-1)\n",
    "y_test_pred = to_categorical(np.array(y_test_pred_sparse), num_classes=n_tags)\n",
    "\n",
    "# compute confusion matrix\n",
    "conf_matrix = np.zeros((n_tags, n_tags))\n",
    "for i,tokens in enumerate(test_tokens):\n",
    "    for j,_ in enumerate(tokens):\n",
    "        class_true = y_test[i,j].argmax()\n",
    "        class_pred = y_test_pred[i,j].argmax()\n",
    "        conf_matrix[class_true,class_pred] += 1\n",
    "names_rows = list(s+'_true' for s in labelclass_to_id.keys())\n",
    "names_columns = list(s+'_pred' for s in labelclass_to_id.keys())\n",
    "conf_matrix = pd.DataFrame(data=conf_matrix,index=names_rows,columns=names_columns)\n",
    "display(conf_matrix)\n",
    "\n",
    "# compute final evaluation measures\n",
    "precision_per_class = np.zeros((n_tags,))\n",
    "recall_per_class = np.zeros((n_tags,))\n",
    "for i in range(n_tags):\n",
    "    \n",
    "    print(\"check gt 0\")\n",
    "    print(conf_matrix.values[i,i])\n",
    "    print(\"\")\n",
    "    if conf_matrix.values[i,i] > 0:\n",
    "        print(\"CLASS = \"+str(i))\n",
    "        precision_per_class[i] = conf_matrix.values[i,i]/sum(conf_matrix.values[:,i])\n",
    "        print(\"precision\")\n",
    "        print(precision_per_class[i])\n",
    "        recall_per_class[i] = conf_matrix.values[i,i]/sum(conf_matrix.values[i,:])\n",
    "        print(\"recall\")\n",
    "        print(recall_per_class[i])\n",
    "        print(\"f1\")\n",
    "        f1_class = 2*(precision_per_class[i]*recall_per_class[i])/(precision_per_class[i]+recall_per_class[i])\n",
    "        print(f1_class)\n",
    "    else:\n",
    "        print(\"no (0) precision or recall for class \"+str(i))\n",
    "precision = np.mean(precision_per_class)\n",
    "recall = np.mean(recall_per_class)\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "print()\n",
    "print('Precision: '+str(precision))\n",
    "print('Recall: '+str(recall))\n",
    "print('F1-measure: '+str(f1))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OWN EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this eval only works, if we use validation_split = 0.2 as additional parameter for model.fit()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
